{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Decision Tree on Smart Alert System"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Imports\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from pathlib import Path\n",
                "from sklearn.model_selection import train_test_split, GridSearchCV\n",
                "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import (\n",
                "    classification_report, confusion_matrix, roc_auc_score, roc_curve,\n",
                "    precision_recall_curve, average_precision_score\n",
                ")\n",
                "from imblearn.over_sampling import SMOTE\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Process Data and Split "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the dataset\n",
                "data_folder = Path.cwd() / \"data\"\n",
                "csv_analysis = data_folder / \"combinedAll.csv\"\n",
                "df = pd.read_csv(csv_analysis)\n",
                "\n",
                "# Aggregate the data by 5-second intervals \n",
                "#Change interval to your desire\n",
                "df['time_interval'] = (df['second'] - 1) // 5\n",
                "\n",
                "aggregated_df = df.groupby('time_interval').agg({\n",
                "    'distance': 'mean',\n",
                "    'motion': 'mean',\n",
                "    'lightIntensity': 'mean',\n",
                "    'occupied': lambda x: x.mode().iloc[0],\n",
                "    'occupied_note': lambda x: x.mode().iloc[0]\n",
                "}).reset_index()\n",
                "\n",
                "# Define features and target\n",
                "X = aggregated_df[['distance', 'motion', 'lightIntensity', 'occupied']]\n",
                "y = aggregated_df['occupied_note']\n",
                "\n",
                "# Split into train and test sets (stratify ensures class balance)\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "# Handle class imbalance using SMOTE\n",
                "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
                "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Decision Tree"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define parameter grid for tuning\n",
                "param_grid = {\n",
                "    'max_depth': [3, 5, 10, None],\n",
                "    'min_samples_split': [2, 5, 10],\n",
                "    'min_samples_leaf': [1, 2, 4],\n",
                "    'criterion': ['gini', 'entropy']\n",
                "}\n",
                "\n",
                "# Initialize Decision Tree Classifier\n",
                "clf = DecisionTreeClassifier(random_state=42)\n",
                "\n",
                "# Use GridSearchCV to find best parameters based on recall\n",
                "grid_search = GridSearchCV(\n",
                "    clf, param_grid, cv=5, scoring='precision', n_jobs=-1, verbose=1\n",
                ") \n",
                "grid_search.fit(X_train_smote, y_train_smote)\n",
                "\n",
                "# Get best model\n",
                "best_clf = grid_search.best_estimator_\n",
                "print(f\"Best parameters: {grid_search.best_params_}\")\n",
                "\n",
                "# Train best model\n",
                "best_clf.fit(X_train_smote, y_train_smote)\n",
                "\n",
                "# Make predictions\n",
                "y_pred = best_clf.predict(X_test)\n",
                "y_proba = best_clf.predict_proba(X_test)[:, 1]\n",
                "\n",
                "# Print classification report\n",
                "print(\"\nClassification Report:\")\n",
                "print(classification_report(y_test, y_pred))\n",
                "\n",
                "# Print confusion matrix\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "print(\"\nConfusion Matrix:\")\n",
                "print(cm)\n",
                "\n",
                "# Compute ROC AUC score\n",
                "roc_auc = roc_auc_score(y_test, y_proba)\n",
                "print(f\"\nROC AUC Score: {roc_auc:.2f}\")\n",
                "\n",
                "plt.figure(figsize=(12, 6))\n",
                "\n",
                "# ROC Curve\n",
                "plt.subplot(1, 2, 1)\n",
                "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
                "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
                "plt.xlabel(\"False Positive Rate\")\n",
                "plt.ylabel(\"True Positive Rate\")\n",
                "plt.title(\"ROC Curve\")\n",
                "plt.legend()\n",
                "\n",
                "# Precision-Recall Curve\n",
                "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
                "avg_precision = average_precision_score(y_test, y_proba)\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(recall, precision, label=f\"Precision-Recall Curve (AP = {avg_precision:.2f})\", color='orange')\n",
                "plt.xlabel(\"Recall\")\n",
                "plt.ylabel(\"Precision\")\n",
                "plt.title(\"Precision-Recall Curve\")\n",
                "plt.legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Plot the decision tree\n",
                "plt.figure(figsize=(20, 10))\n",
                "plot_tree(\n",
                "    best_clf,\n",
                "    feature_names=X_train_smote.columns if hasattr(X_train_smote, 'columns') else None,\n",
                "    class_names=['Not Occupied', 'Occupied'],\n",
                "    filled=True,\n",
                "    rounded=True,\n",
                "    fontsize=10\n",
                ")\n",
                "plt.title(\"Best Decision Tree\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Random Forrest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define parameter grid for tuning \n",
                "param_grid_rf = {\n",
                "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
                "    'max_depth': [3, 5, 10, None],    # Maximum depth of the tree\n",
                "    'min_samples_split': [2, 5, 10],  # Minimum samples required to split a node\n",
                "    'min_samples_leaf': [1, 2, 4],    # Minimum samples required at a leaf node\n",
                "    'criterion': ['gini', 'entropy']  # Splitting criterion\n",
                "}\n",
                "\n",
                "# Initialize Random Forest Classifier\n",
                "clf_rf = RandomForestClassifier(random_state=42)\n",
                "\n",
                "# Use GridSearchCV to find best parameters based on precision\n",
                "grid_search_rf = GridSearchCV(\n",
                "    clf_rf, param_grid_rf, cv=5, scoring='precision', n_jobs=-1, verbose=1\n",
                ")\n",
                "grid_search_rf.fit(X_train_smote, y_train_smote)\n",
                "\n",
                "# Get best model\n",
                "best_clf_rf = grid_search_rf.best_estimator_\n",
                "print(f\"Best parameters: {grid_search_rf.best_params_}\")\n",
                "\n",
                "# Train best model\n",
                "best_clf_rf.fit(X_train_smote, y_train_smote)\n",
                "\n",
                "# Make predictions\n",
                "y_pred_rf = best_clf_rf.predict(X_test)\n",
                "y_proba_rf = best_clf_rf.predict_proba(X_test)[:, 1]\n",
                "\n",
                "# Print classification report\n",
                "print(\"\nClassification Report:\")\n",
                "print(classification_report(y_test, y_pred_rf))\n",
                "\n",
                "# Print confusion matrix\n",
                "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
                "print(\"\nConfusion Matrix:\")\n",
                "print(cm_rf)\n",
                "\n",
                "# Compute ROC AUC score\n",
                "roc_auc_rf = roc_auc_score(y_test, y_proba_rf)\n",
                "print(f\"\nROC AUC Score: {roc_auc_rf:.2f}\")\n",
                "\n",
                "# Plot ROC Curve and Precision-Recall Curve\n",
                "plt.figure(figsize=(12, 6))\n",
                "\n",
                "# ROC Curve\n",
                "plt.subplot(1, 2, 1)\n",
                "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_proba_rf)\n",
                "plt.plot(fpr_rf, tpr_rf, label=f\"ROC Curve (AUC = {roc_auc_rf:.2f})\")\n",
                "plt.xlabel(\"False Positive Rate\")\n",
                "plt.ylabel(\"True Positive Rate\")\n",
                "plt.title(\"ROC Curve\")\n",
                "plt.legend()\n",
                "\n",
                "# Precision-Recall Curve\n",
                "precision_rf, recall_rf, _ = precision_recall_curve(y_test, y_proba_rf)\n",
                "avg_precision_rf = average_precision_score(y_test, y_proba_rf)\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(recall_rf, precision_rf, label=f\"Precision-Recall Curve (AP = {avg_precision_rf:.2f})\", color='orange')\n",
                "plt.xlabel(\"Recall\")\n",
                "plt.ylabel(\"Precision\")\n",
                "plt.title(\"Precision-Recall Curve\")\n",
                "plt.legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "#Feature Impotance Plot\n",
                "\n",
                "importances = best_clf_rf.feature_importances_\n",
                "feature_names = X_train_smote.columns if hasattr(X_train_smote, 'columns') else [f'Feature {i}' for i in range(X_train_smote.shape[1])]\n",
                "indices = np.argsort(importances)[::-1]\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.title(\"Feature Importances from Best Random Forest\")\n",
                "plt.bar(range(len(importances)), importances[indices], align='center')\n",
                "plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=45, ha='right')\n",
                "plt.ylabel(\"Importance Score\")\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}